# Module 10: Using Azure Machine Learning Models
# Lab: Using Machine Learning experiments

### Scenario
You work as a data scientist at Adatum Consultants, a company that provides machine learning services and advice for a range of clients. Your client has asked you to publish a machine learning model that predicts whether adults have an income of more or less than USD50,000 a year. Your client runs an e-commerce company and they want to show a different home page to users depending on their annual income.
You will publish this model and consume predictions using HTTP calls via Fiddler and the BES endpoint with a C\# application. You will also investigate scored predictions using Microsoft Excel.

### Objectives
After completing this lab, you will be able to:
-   Publish a Machine Learning model.
-   Consume a Machine Learning model.

### Lab Setup
Estimated Time: 75 minutes
Virtual machine: **20774A-LON-DEV**
User name: **ADATUM\\AdatumAdmin**
Password: **Pa55w.rd**

## Exercise 1: Publish a Machine Learning model

### Scenario
In this exercise, you will modify and publish a sample Machine Learning experiment, that uses Two-Class Boosted Decision Tree to predict the income of an adult based on features regarding his or her profession and demographics.

The main tasks for this exercise are as follows:
1. Create a standard Machine Learning Workspace
2. Open a sample experiment
3. Publish the experiment as a web service
4. Add export path as a web service parameter
5. Deploy the web service

#### Task 1: Create a standard Machine Learning Workspace
1.  Create a Machine Learning Workspace using the following information:
    - Workspace name: **&lt;your name&gt;-workspace**
    - Subscription: **Azure Pass**
    - Resource group: (create new) **workspacerg**
    - Location: choose the nearest location
    - Storage account: (create new) accept default **&lt;unique&gt;**
    - Web service plan: (create new) accept default
    - Web service plan pricing tier: **DevTest Standard**

#### Task 2: Open a sample experiment
1.  In Machine Learning Studio, create a new experiment from **Sample 5: Train, Test, Evaluate for Binary Classification: Adult Dataset**.
2.  This sample takes census data details and attempts to predict adult income. It trains one machine learning model, the **Two-Class Boosted Decision Tree**, and evaluates the results.
3.  Familiarize yourself with the experiment by looking at the **Select Columns in Dataset** and **Train Model** modules.
4.  Run the experiment.

#### Task 3: Publish the experiment as a web service
1.  Create a predictive experiment, using the click **Predictive Web Service (Recommended)** option.
2.  Add an **Export Data** module, and connect the **Score Model** output to the **Export Data** module.

#### Task 4: Add export path as a web service parameter
1.  Configure the Export Data module, with the following information:
    -   Azure account name: **&lt;*your storage account*&gt;**
    -   Azure account key: **key1** from your Azure storage access keys
    -   Path to Blob beginning with container: **container1/output1.csv** (and set this path as a web service parameter)
2.  Change the web service parameter name to **blobpath**.
3.  Change the Azure Blob storage write mode to **Overwrite**.
4.  Add a **Select Columns in Dataset** module, and select the **Scored Labels** and **Scored Probabilities** columns.
5.  Connect the output of **Select Columns in Dataset** to the input for **web service output**.
6.  Run the experiment.

#### Task 5: Deploy the web service
1.  Deploy the experiment as a web service, using the select **New Web Services Experience preview** option, and using the price plan you specified in Task 1.
2.  Wait until the **Machine Learning Web Services** page has opened, before continuing to the next exercise.

**Results**: At the end of this exercise, you will have published a Machine Learning model.

## Exercise 2: Consume a Machine Learning model

### Scenario
In this exercise, you will consume your published Machine Learning experiment, using several methods. First you will use the Fiddler Composer tool to test the Request Response Service, by sending HTTP requests that you define. Then you will use Visual Studio®, and C\# code, to test the Batch Execution Service. Finally, you will use the Microsoft Excel Machine Learning add-in, with the Request Response Service.

The main tasks for this exercise are as follows:
1. Consume web services using RRS
2. Consume web services using BES
3. Consume web services in Excel

#### Task 1: Consume web services using RRS
01. Download Fiddler from **http://www.telerik.com/download/fiddler**, and install it using the default options.
02. Start **Fiddler**, and in the **AppContainer Configuration** dialog box, click **No**.
03. Configure Fiddler so that it does not capture traffic.
04. In Fiddler, open the **Composer** page, and change GET to **POST**.
05. Switch to the Machine Learning Web Services webpage, and click **Consume**.
06. Copy **Request-Response**, and paste this into the **Composer** address box in Fiddler.
07. Copy the **Primary Key** from the **Machine Learning Web Services** page.
08. In the Fiddler Composer body text box, under **User-Agent: Fiddler**, create a new line, type **Authorization: Bearer**, and then paste your primary key, ensuring that there is a space before the pasted key.
09. Create a new line, and then type **Content-Type:Application/JSON**.
10. On the **Machine Learning Web Services** page, click **Swagger API**, and then click **Submit request**.
11. Select the **Execution request** **body**, and copy it to the clipboard.
12. Paste this code into the Fiddler **Request Body** box.
13. Update the body request so that it matches the following code example:
    ```
	{
	"Inputs": {
	"input1": [
		{
		"age": 45,
		"workclass": "Private",
		"fnlwgt": 432123,
		"education": "Bachelors",
		"education-num": 14,
		"marital-status": "Divorced",
		"occupation": "Sales",
		"relationship": "Not-in-family",
		"race": "White",
		"sex": "Male",
		"capital-gain": 2174,
		"capital-loss": 0,
		"hours-per-week": 60,
		"native-country": "United-States",
		"income": "<=50K"
		}
	]
	},
		"GlobalParameters": {
		"blobpath": "container1/RRSprediction"
		}
	}
    ```
14. In Fiddler, execute the request.
15. Open the results, and notice that the actual value of income and predicted income are different values.
16. Make the following changes in **Request Body**:
    ```
	"race": "Asian",
	"sex": "Female",
    ```
17. Execute the request, and view the results.
18. Try some more requests with different feature inputs, and then when they are completed, close Fiddler.

#### Task 2: Consume web services using BES
01. In **Visual Studio 2015**, create a new classic .NET console application named **BESService**.
02. Install the **Microsoft.AspNet.WebApi.Client** NuGet package.
03. Add the **WindowsAzure.Storage** NuGet package.
04. Switch to the Machine Learning Web Services webpage, and click **Consume**.
05. Copy the **Request-Response** sample code for **C\#**, and paste this into the **Program.cs** file, replacing the existing contents.
06. Configure Visual Studio options, so that line numbers are displayed.
07. In **Program.cs**, navigate to line 98, and replace **myresultsfile.file\_extension**, with **E:\\\\BESresults.csv**.
08. In **Program.cs**, navigate to line 163, and replace **mystorageacct**, with your Azure storage account name.
09. In **Program.cs**, navigate to line 164, and replace **a\_storage\_account\_key**, with your primary Azure storage key.
10. In **Program.cs**, navigate to line 165, and replace **mycontainer**, with **bescontainer**.
11. In **Program.cs**, navigate to line 168, and replace **abc123**, with your web services API key.
12. In **Program.cs**, navigate to line 173, and replace **input1data.file\_extension**, with **E:\\\\Labfiles\\\\Lab10\\\\Starter\\\\Binary Classification dataset.csv**.
13. In **Program.cs**, navigate to line 174, and replace **input1datablob.file\_extension**, with **BESdata.csv**; repeat this step at line 187.
14. In **Program.cs**, navigate to line 198, and replace **output1results.file\_extension**, with **BESoutput.csv**.
15. In **Program.cs**, navigate to line 205, and replace **"blobpath", ""**, with **"blobpath", "bescontainer/BESpredictions.csv"**.
16. In **Program.cs**, navigate to line 292, and type **Console.ReadLine();** at the end of the line.
17. Run the solution, and wait until you see the following message before continuing this exercise:
    ```
	The results for output1 have been written to the file E:\\BESresults.csv
    ```
18. Close the Visual Studio console.
19. Save **Program.cs**.
20. Open the **bescontainer** blob container in the Azure Portal, and download and save **BESpredictions.csv**.
21. Open **BESpredictions.csv** in Microsoft Excel, and note that the file contains data, with a scored probability for each row.
22. Use Microsoft Excel to open **E:\\BESresults.csv**, and note that this file contains only the scored probabilities.
23. Close Microsoft Excel and Visual Studio.

#### Task 3: Consume web services in Excel
01. Go to **https://store.office.com/**, and add the **Azure Machine Learning** add-in to Microsoft Excel.
02. Configure Microsoft Excel to trust this add-in, and to enable editing for the worksheet.
03. In the **Machine Learning** add-in, add a web service.
04. Copy the **Request-Response** string from the **Machine Learning Web Services** page, and paste this string into the **URL** box in the **Machine Learning** add-in.
05. Copy the **Primary Key** from the **Machine Learning Web Services** page, and paste this key into the **API key** box in the **Machine Learning** add-in.
06. Switch to Microsoft Excel, and in the **API key** box, paste the key you copied in step 13.
07. Open **E:\\Labfiles\\Lab10\\Starter**\\**Binary Classification dataset.csv**.
08. Copy all the data, and then paste the contents into a new worksheet in the **Azure-Machine-Learning** spreadsheet.
09. Delete the top row to remove the column labels.
10. Click **Add**, at the bottom of the Machine Learning add-in.
11. In the **Machine Learning** add-in pane, under **Input**, click to select all the available data as input.
12. Clear the **My data has headers** check box.
13. In the box under **Output**, type **P1**.
14. Clear the **Include headers** check box.
15. In the **blobpath** box, type **container1/excelprediction.csv**, and then click **Predict**.
16. Note that columns P and Q now contain the scored labels, and predictions/probabilities for all rows of data.
17. Open the **container1** blob container in the Azure Portal, and download and open **excelprediction.csv**.
18. Note that this file contains the features and scores from your most recent Excel test.
19. Exit Excel, without saving any changes.
20. Use the Azure Portal to delete the resource group you used during this exercise, and all associated resources.
21. Close Internet Explorer, and click **Close all tabs**.

**Results**: At the end of this exercise, you will have consumed a Machine Learning model using the Request Response Service, the Batch Execution Service, and Microsoft Excel.

**Question:** Where can having the Excel add-in help you?

**Question:** What kinds of modeling could students add to the Gallery?

©2017 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.